# Decorating the North Pole in Hardcaml

[![AoF 2025 - Puzzle Tests](https://github.com/kagandikmen/aof-2025-temp/actions/workflows/run_tests.yaml/badge.svg)](https://github.com/kagandikmen/aof-2025-temp/actions/workflows/run_tests.yaml)

This repository contains my solutions to the [Advent of FPGA 2025](https://blog.janestreet.com/advent-of-fpga-challenge-2025/) challenge from Jane Street. It implements the solutions in Hardcaml, which is an "embedded hardware design domain specific language (DSL) implemented in OCaml" [[1]](https://arxiv.org/abs/2312.15035).

This repository is a fork of the [Hardcaml Arty](https://github.com/fyquah/hardcaml_arty) project, which is a Hardcaml library to interface with Arty A7 boards.

## Advent Calendar (aka Project Progress)

██████████████████████████████░░░░░░&nbsp;&nbsp;&nbsp;83.3%

0️⃣1️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣2️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣3️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣4️⃣ ✅  
0️⃣5️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣6️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣7️⃣ ✅ &nbsp;&nbsp;&nbsp; 0️⃣8️⃣ ✅  
0️⃣9️⃣ ✅ &nbsp;&nbsp;&nbsp; 1️⃣0️⃣ ⬜ &nbsp;&nbsp;&nbsp; 1️⃣1️⃣ ✅ &nbsp;&nbsp;&nbsp; 1️⃣2️⃣ ⬜ 

## Project Structure

```text
lib
├── hardcaml_aof        # Advent of FPGA solution library
├── hardcaml_aof_test   # Advent of FPGA testbench library
└── hardcaml_arty       # Hardcaml Arty (for Arty A7 w/ Hardcaml)
src
└── dayXX
    └── dayXX.ml        # Solution for the puzzle of day XX
test
└── dayXX
    ├── input.txt       # Puzzle input of the day
    ├── ref.py          # Reference solution in Python
    └── test_dayXX.ml   # Testbench for the solution of the day
```

Besides, you can refer to `src/old` and `test/old` for older solutions and their testbenches.

## Getting Started

To run the tests, you must have OCaml and opam on your machine. Refer to [OCaml's official installation guide](https://ocaml.org/docs/installing-ocaml) to install them.

After the installation, run:

```bash
opam init
opam switch create hardcaml 4.13.1
opam switch hardcaml
eval $(opam env)
opam repo add janestreet-bleeding https://ocaml.janestreet.com/opam-repository
opam repo add janestreet-bleeding-external https://github.com/janestreet/opam-repository.git#external-packages
opam install ocaml-lsp-server odoc ocamlformat utop
opam install hardcaml hardcaml_waveterm ppx_jane ppx_expect ppx_deriving_hardcaml
```

This will create an opam switch `hardcaml` in version 4.13.1, switch to it, and install required dependencies.

## Running the Tests

Given you have all prerequisites in place, run:

```bash
dune runtest
```
from the project root to run all the tests at once. You can also use:

```bash
dune runtest test/dayXX test/dayXY
```
to specify which tests you want to run. For the waveform files generated by the testbenches, navigate to the `/tmp/` directory on your machine.

**IMPORTANT:**

Advent of Code puzzle inputs differ by user. The expected values embedded into the testbenches may (and most likely will) become wrong if you replace my puzzle inputs with yours. You can, however, update the expected values after running the reference Python solution if you wish to use your own personal puzzle input.

**ALSO IMPORTANT:**

I used OCaml 4.13.1 working through the puzzles. You may observe peculiarities if you use a different version. (The compiler complaining because `of_int` is used instead of `of_int_trunc` is a strong sign thereof, for example.) Please check you are on the right version by using:

```bash
opam switch show
```

<details>
<summary>Are you on a different version?</summary><br>

If you are using a different version of OCaml, run:

```bash
opam switch create hardcaml 4.13.1
opam switch hardcaml
eval $(opam env)
```

to create a new opam switch with the right version, and switch to it. You can also refer to the [Github Actions workflow configuration](.github/workflows/run_tests.yaml) of this repository for the exact specifics of the intented setup.

</details>

## Solution Details

<details>
<summary><b>Day 1:</b> Secret Entrance</summary><br>

<h2>Day 1: Secret Entrance</h2>

### Summary

The puzzle of day 1 consists of two steps. For a given turning sequence, it needs to be computed:

- how many times the lock mechanism of a door stops at zero (Step 1)
- how many times the lock mechanism of a door hits zero (Step 2)

The key detail is that it is a circular lock that is being turned. So the counter wraps at 100. (0 and 99 are neighbors.)

### My Solution

The state machines in [my solution](src/day01/day01.ml) are fairly simple. You can find them below. `States` signifies the "main states," which relate to general control of the execution. `Compute_states` signifies the execution steps of the "knob turner" logic that starts running in the background as input text starts flowing to the FPGA through the UART bus.

```ocaml
module States = struct
  type t = 
    | Idle
    | Receive
    | Compute
    | Done
  [@@deriving sexp_of, compare, enumerate]
end

module Compute_states = struct
  type t =
    | Idle
    | Turn
  [@@deriving sexp_of, compare, enumerate]
end
```

The FPGA starts at `Idle`. In this state it is doing nothing, except for the fact that it is listening to the UART bus for the special ASCII control character "start of text." Once it is received, the FPGA transfers to the state `Receive` where it starts receiving unprocessed raw input text through the UART bus. The logic parses every line, registering the R or L at the start as positive or negative turn, and at each line break it saves the received turn value into its 16-bit wide FIFO. When the ASCII control character for "end of text" is received, the logic moves onto the state `Compute` where it waits for the knob turner logic to complete. When it is complete, it concludes everything by moving onto the state `Done`. 

The knob turner logic is another state machine (a very simple one) that "runs in the background" while the FPGA is actually still listening to the UART bus for new knob turn data. Knob turner logic is triggered when the FIFO is no longer empty. This causes the knob turner state machine to move to its only active state `Turn`. In this state the turn magnitude and direction is analyzed and the values for part 1 and part 2 of the puzzle are updated accordingly. Because this logic is fast enough to conclude before the next turn is saved into the FIFO, the FIFO depth requirement is extremely low for this application.

In my [older solution](src/old/day01/day01.ml) for this puzzle, I had a stateless design which required the values to be converted into 16-bit integers on the host side. As I am on a newfound quest toward zero host-side processing, I felt a necessity to move away from this old design. To my surprise, the new design is 28% faster!

### Suggestions

The knob turner logic is both much faster than the UART transmission and runs parallel to it. Therefore the UART transmission is the overwhelmingly biggest performance bottleneck. As one of my main design concerns is real-world FPGA deployability, I will not move away from the UART transmission. However, if you don't feel bounded by this, feel free to attack the data transmission first. You may need to increase the FIFO depth as you move towards faster transmission protocols. 

To avoid costly division logic, I used a 10-step subtraction routine instead of dividing the rotation magnitude by 100. The same routine (function `divmod100`) also serves as modulo. It uses a trick, however: It makes use of the fact that our turns in the puzzle input never exceed 1000. In case you have bigger turn magnitudes, you need to increase the number of steps by modifying it.

<br><br><br></details>

<details>
<summary><b>Day 2:</b> Gift Shop</summary><br>

<h2>Day 2: Gift Shop</h2>

### Summary

The puzzle of day 2 also consists of two parts. For any given range, the hardware needs to compute how many integers are in the range with a digit sequence

- that is a subsequence repeating itself twice (Step 1)
- that is a subsequence repeating itself **at least** twice (Step 2)

### My Solution

**IMPORTANT:** For further reference, I called the integers that fulfill the part 1 criteria "silly numbers." Likewise, an integer is a "goofy number" if it fulfills the criteria for part 2. Don't ask why I did this :D

The state machines in [my solution](src/day02/day02.ml) are as below. `States` is the "main state machine" whereas `Compute_states` are the states of the "processing engine." Main state machine is responsible for receiving input and general execution control, whereas the compute states govern the timing with which the processing engine goes through the bounds.

```ocaml
module States = struct
  type t =
    | Idle
    | Receive
    | Compute
    | Done
  [@@deriving sexp_of, compare, enumerate]
end

module Compute_states = struct
  type t =
    | Idle
    | Read
    | Init
    | Evaluate
    | Next
  [@@deriving sexp_of, compare, enumerate]
end
```

At program start, the FPGA is in state `Idle` where it listens to the UART bus for the ASCII control character "start of text." After sending this character, the host sends the puzzle input text with no preprocessing. The flowing characters are registered as valid input data on the FPGA side, which is now in `Receive` state. The FPGA parses the incoming characters and saves the received range bounds into two FIFOs, one for lower bounds and one for upper bounds. The values are converted into binary coded decimal (BCD) before being saved. When the host sends the character "end of text," the FPGA moves onto the state `Compute` where it waits for the processing engine to complete bound processing. Once the processing engine is back in idle state, the main state machine concludes everything by moving further to its state `Done`.

The moving of the processing engine out of `Idle` is triggered by the arrival of first bounds in the FIFOs. The biggest advantage here is that the processing engines don't need to wait for full input arrival. Once the first bounds are received, they can start computing while the other bounds are still being transmitted.

The processing engine does not check every single integer in the range to figure out if it is silly and/or goofy. That is sometimes billions of integers to check. Therefore, the processing engine comes from the other side. It goes through all silly/goofy numbers and checks if they are in the given integer range. This is done in state `Evaluate` of the processing engine, and it has proven to be the faster approach.

In my [older solution](src/old/day02/day02.ml) for this puzzle, I was:

- turning range bounds into 40 bit integers on the host side,
- iterating over all the integers in the range on the host side, sending every single one through UART,
- computing on the FPGA (no state machine) if the latest-received integer is silly/goofy.

Horrible solution, I know. The new one is incomparably better.

### Suggestions

Because the UART transmission continues running "in the background" while the first ranges are already being processed, the UART transmission is not the performance bottleneck in this application. The by far longest chunk of execution is the evaluation state of the processing engine. Currently, the FPGA dynamically computes all silly/goofy numbers on the run. I am thinking a possible next step could be to explore what happens if we made this computation static. In the end, the set of all silly/goofy numbers does not change from range to range. However, I don't know what kind of effect this would have on area/resource usage. I also don't know if this increase in logic footprint would result in a performance increase good enough to justify it. You can try this out and let me know, don't hesitate to create an issue or pull request.

<br><br><br></details>

<details>
<summary><b>Day 3:</b> Lobby</summary><br>

<h2>Day 3: Lobby</h2>

### Summary

The puzzle of day 3 also consists of two parts. For any given digit sequence, the puzzle requires us to compute what is the highest achievable value after deleting a given number of digits. In the first parts, 2 digits are left; in the second part, 12 are left.

### My Solution

In [my solution](src/day03/day03.ml), the raw text input received through the UART bus is processed as digits arrive one by one. In this puzzle, each sequence has exactly 100 digits. This means we are allowed to drop 98 of them for the first part of the puzzle. 88 of them for the second part, likewise. For any given number of digits to leave, k, the FPGA first computes how many digits can be dropped per bank, 100 - k. Then it processes every arriving digit immediately by comparing it to the already-picked values. Given there are still enough remaining "drop credits" at the time of arrival, the previously-picked digits are dropped if they are smaller than the incoming one. Finally, once all 100 digits are processed, the remaining digits are converted to decimal and added to a running total.

### Suggestions

My implementation hardcodes the bank width 100 to the logic. Although this is easily changeable in the source code, one may want a design capable to adjust itself for different sequence widths. I can think of two ways:

- **Accepting the whole sequence, and then starting the computation:** In such an implementation all digits of the sequence would first be transmitted and saved by the FPGA. Once the FPGA is "notified" that the transmission is completed, it would start to iterate over the digits from the most significant to the least significant.
- **Sending the sequence width beforehand:** In such an implementation the host would first send the width of the sequence and then start sending the digits one by one. The digits would still all be processed immediately on arrival.

I personally like the second much more. The first one asks for a lot more memory, and requires back-and-forth communication between the host and the FPGA. Not to mention one will have to set a maximum sequence width anyways, as the number of registers is fixed at design time. The second one handles the problem with much less memory overhead, and it does not require the host to wait for a done signal from the FPGA either. As both approaches require host-side processing, I opted for neither of them.

<br><br><br></details>

<details>
<summary><b>Day 4:</b> Printing Department</summary><br>

<h2>Day 4: Printing Department</h2>

### Summary

The puzzle of day 4 requires us to solve a k-core peeling algorithm; 4-core in this case. The first step asks for how many vertices are removed in the first iteration, whereas the second step asks for how many are removed for an iteration count approaching infinity.

### My Solution

[My solution](src/day04/day04.ml) implements an iterative, multi-pass, memory-resident algorithm with the following finite state machine:

- **LOAD**: In this state, all field info is transmitted to the FPGA via UART. The dots and ats are transmitted in ASCII format without any host processing. The FPGA receives and stores them one by one into a 140x140 grid. Each cell of the grid has the following contents:

```ocaml
module Cell = struct
  type 'a t =
  {
    is_roll: 'a;
    is_accessible: 'a;
  }

  ...
end
```

Both `is_roll` and `is_accessible` are 1-bit wide. The state LOAD only writes `is_roll` though, `is_accessible` is computed in the state MARK. After the loading of all fields is complete, the FSM continues with the state MARK.

- **MARK**: This state iterates over all cells, computes their accessibility, and sets their `is_accessible` field accordingly. An accessible cell is a cell that has less than 4 neighbors occupied by paper rolls. Once all cells are iterated, the FSM continues onto the state REMOVE.
- **REMOVE**: This state iterates over all cells once again, and sets their `is_roll` field zero if they are both occupied by a roll and set accessible by the MARK state. (This is essentially "removing the paper roll.") Once the iteration is done, the logic checks if `max_passes` number of MARK-REMOVE iterations is achieved. If yes, then the FSM moves onto DONE. If not, then it returns back to MARK for another iteration. For the case where `max_passes` is set to zero, the MARK-REMOVE loop continues forever until there are no more rolls to remove. The number of removed rolls is accumulated in the register `total_removed`.
- **DONE**: This is the state the logic arrives at after breaking from the MARK-REMOVE loop. The FPGA signals back to the host that the computation is done, so the host knows that `total_removed` is stabilized.

`max_passes` is not a compile-time constant. It is implemented as an input signal to the FPGA. I presume it would be fairly easy to make it a compile-time constant, though.

The grid dimensions are a compile-time constant. That each cell is implemented as a 2-bit field helps minimize the memory footprint.

### Suggestions

The algorithm in itself is unfortunately not very hardware-friendly. The 140x140 grid is therefore a necessity rather than a design choice. To improve performance, another algorithm could be implemented to keep track of the roll removals of the previous row. This would enable the two states MARK and REMOVE to be merged together, resulting in sizeable performance boost.

<br><br><br></details>

<details>
<summary><b>Day 5:</b> Cafeteria</summary><br>

<h2>Day 5: Cafeteria</h2>

### Summary

Like the others, the puzzle for day 5 consists of two steps. It is based on a text input that consists of lines that are either integers (IDs) or integer ranges. In the first step, it is computed how many of the IDs fall on at least one of the ranges. In the second step, it is computed how many integers in general fall on at least one of the ranges. The main challenge, especially in step two, is that the ranges both overlap and come unsorted.

### My Solution

[My solution](src/day05/day05.ml) implements a data structure called "Package" to standardize sending of ranges, ingredient IDs, and other sorts of control signals. Every package consists of an 8-bit flag and 64-bit payload. The 8-bit flag:

- `0x01` signals that the payload is the lower bound of a new range,
- `0x02` signals that the payload is the upper bound of the range the lower bound of which was just sent,
- `0x03` signals "section change," which means that all ranges are done being sent and ingredient IDs will follow,
- `0x04` signals that the payload is an ingredient ID,
- `0xFF` signals EOF.

Other 8-bit values are invalid as flags. My solution then implements the following state machine:

```ocaml
module States = struct
  type t =
    | Read_ranges
    | Read_ids
    | Scan
    | Merge
    | Count
    | Done
  [@@deriving sexp_of, compare, enumerate]
end
```

The FPGA, starting in the state `Read_ranges`, first reads all the ranges in the order they are fed to the UART bus by the host. The moment the host signals a section change, the logic transfers to the state `Read_ids`. When the host is done with sending all IDs, it signals EOF, and the logic starts sorting the ranges. The sorting process (selection sort) starts with the state `Scan`. In this state, the FPGA looks for the range with the lowest lower bound that is not marked as "used" yet. Then it moves onto the state `Merge`, which is where we scan through all unused ranges once again for candidates eligible for a range merge. Then, if there are still unused ranges left, the FPGA goes back to the state `Scan`. Once the `Scan`-`Merge` loop is completed, the logic goes into the `Count` state. In this state, we count how many of the IDs fall in any one of the merged ranges. Finally, the FPGA arrives at the state `Done`, where it signals back to the host that the computation is successfully completed.

### Suggestions

I don't know how it could be done, but a better sorting & merging algorithm would be much appreciated. Sorting is not particularly hardware-friendly. Selection sort, the sorting algorithm I implemented, has a time complexity of O(n^2). If there is any possibility to sort the ranges before feeding them into the FPGA, this would prevent a lot of computation & logic complexity from happening in the first place.

Another suggestion could be made about the packaging, in case we are on a quest to save every single cycle possible. The section change and EOF signals do not send any meaningful payload, but the FPGA waits for this payload to be fully sent before going forward with the signaled operation. In current implementation, the host fills the payload field with zeros. This is not even remotely the performance bottleneck of the application, but fixing it would save a couple cycles.

<br><br><br></details>

<details>
<summary><b>Day 6:</b> Trash Compactor</summary><br>

<h2>Day 6: Trash Compactor</h2>

### Summary

Like the others, the puzzle for day 6 consists of two parts. It is based on a text input that consists of a matrix of integers, followed by a final row of operation signs. (Either addition or multiplication in this case.) The integers (and the operator) that are found in the same column belong to each other and constitute an operation. (I called this union of integers and operator an "opblock.") In part 1, the integers are to be parsed left to right, whereas in part 2 they are parsed from top to bottom.

### My Solution

[My solution](src/day06/day06.ml) starts its life in `Idle` state and immediately starts listening to the UART bus. When the host sends the ASCII value for "start of text," the FPGA transfers into the state `Receive`. In this state, the FPGA saves the characters of the incoming text (with zero preprocessing this time) one by one in its RAM.

When the host transfers the ASCII value "end of text," the FPGA moves onto the state `Find_opblk_start`. Then moving further onto the state `Find_opblk_end`, the FPGA iterates over all columns to figure out at which column the next opblock starts and ends. (Bear in mind our columns are one character wide.) Once the borders are figured out, the FPGA continues with the states `Setup_compute` and `Compute`, the latter of which activates the "secondary state machines." These secondary state machines are another type of state machine, which we instantiate twice. They work simultaneously; and they only differ in the specifics of the computation one of their states includes. The first state machine is for part 1, and the second is for part 2. So, for each opblock, the parts 1 and 2 are computed in parallel, saving latency.

When both secondary state machines arrive at their `Done` state and return, the primary state machine adds the return values into a running total and continues with the next iteration of the loop: `Find_opblk_start`-`Find_opblk_end`-`Setup_compute`-`Compute`. After all opblocks are processed this way, the running totals are returned to the host.

There was an [older solution](src/old/day06/day06.ml) for this puzzle where the characters were saved in an array called `grid` instead of a RAM. As it takes linear time to index, read, or write to arrays, this older implementation was embarrassingly slow. The random access into the "character memory" as offered by the newer RAM-based implementation is incomparably faster. With the full puzzle input, the newer solution takes ~4 minutes to simulate on my machine. The older solution was still going strong when I terminated it after an hour.

### Suggestions

I feel like the main state machine could be made more compact by removing the state `Setup_compute`. I am planning to revisit this puzzle to see if the compute setup can be moved to the `Find_opblk_end` and/or `Compute` states.

Another idea would be to implement "opblock engines" for each opblock received/saved. Iterating over the rows (either during transmission or after it,) each value on the row would be sent to its dedicated opblock engine, which would both add and multiply all the operands as they come. Once the final row arrives with the correct operation, the opblock engine would then already have the result and return it immediately. 

The biggest performance bottleneck of the new version of the application is the UART transmission, which consumes around 95% of the cycles. I intend to keep the UART bus for seamless FPGA deployment in the future. In case your situation allows you to opt for a parallel (or simply faster) protocol, this opblock engines idea would be worth considering.

But all this under a condition: As the relation "columns per row" grows, this idea of parallel processing could prove impractical due to power and/or area concerns.

<br><br><br></details>

<details>
<summary><b>Day 7:</b> Laboratories</summary><br>

<h2>Day 7: Laboratories</h2>

### Summary

The part 1 of the seventh puzzle requires us to find how many times a beam split event happens in a given positioning of beam inputs and splitters. The second part requires the computation of how many alternative paths there are for a beam to follow from the beginning (top) until the end (bottom.)

### My Solution

In [my solution](src/day07/day07.ml), the input text is first sent through the UART bus to the FPGA without any preprocessing. The beginning of the transmission triggers the `Idle` -> `Receive` state transition on the FPGA side, whereas the end of transmission triggers `Receive` -> `Compute`. The characters, which were saved into a 256x256 RAM in `Receive` state, are iterated over during `Compute`. At each row, the logic compares the current row with the row before, and saves both 

- number of split events in that row
- how many alternative ways there are for the beam to access each field of the current row.

At the end of each row, the logic transfers to the state `Switch_rows` and then goes back to the state `Compute` for the next row. Once the `Compute`-`Switch_rows` loop is completed for every row, the FPGA concludes the computation with the states `Conclude` and `Done`, respectively. Just as usual, a done signal is raised at the end to notify the host.

### Suggestions

This puzzle is actually very suitable for parallel processing of the characters in a row. The moment all characters are successfully transmitted and saved, the control logic could iterate over the rows from top to bottom, and feed all the characters one-by-one to an array of "column engines." Each column engine would have a small memory keeping track of 

- current presence of beam
- number of alternative paths to arrive at that column for the current row index.

However, judging by the waveform I can say that more than 95% of the cycles are spent during the UART transmission. So the row-wise + column-wise iteration is not the performance bottleneck of the application. I intend to keep the UART transmission for the sake of seamless future FPGA deployment, but in case you are fine with replacing it with some parallel/faster transmission method, this "column engines idea" could prove beneficial for you.

<br><br><br></details>

<details>
<summary><b>Day 8:</b> Playground</summary><br>

<h2>Day 8: Playground</h2>

### Summary

For the puzzle of day 8 we have points in 3D space. And these points need to be connected starting from the shortest-distanced pair. Connected points constitute a "circuit." The first part of the puzzle asks for the sizes of three biggest circuits after a certain number of connections. The second part asks us to connect until all points are connected (directly or indirectly) and then asks for the x-coordinates of the points of the latest-connected pair.

### My Solution

[My solution](src/day08/day08.ml) first receives the text input through the UART connection without any host-side preprocessing. It then goes over all possible connections to compute the distances between point pairs. I used squared distances in my solution to spare costly square root logic. Because we are interested in the order of the distances only, not the real values themselves, working with squared distances does not affect correctness in this case.

After all distances are computed, the FPGA sorts the connections by ascending distance. For this, I used bitonic sort because of its somewhat hardware-friendly nature. 

The logic then continues by initiating the "graph," which is just two arrays in this case. The idea is similar to what I implemented in [my Python reference solution](test/day08/ref.py), which is basically [Kruskal's algorithm](https://en.wikipedia.org/wiki/Kruskal%27s_algorithm). In this application of the algorithm, we treat the points as the vertices of a graph, and the connections between them as the edges. We use two arrays (lists in Python,) both with a size equal to the number of points. The first array is called `parents` and stores the parent of each vertex. For each circuit one of the vertices is the "eldest parent" or "root," which means it directly or indirectly fathers all the other vertices in the circuit. (It actually does not matter much which vertex the root is.) The second array is called `sizes` and for each root vertex it stores the size of its circuit. For vertices that are not the root of the circuit, the size array does not store any meaningful value.

After the bitonic sort, the FPGA continues by setting the graph up, and then it starts fetching the possible connections one by one, starting from the shortest-distance one. If the vertices are not already in the same circuit, their circuits are merged. Once all vertices are part of the same circuit, the FPGA concludes the computation. As usual, the host is notified for the end of computation through a done signal.

### Suggestions

I have to admit that this was the most difficult puzzle so far; the task does not lend itself well to hardware. Sorting is extremely costly, which is why I even needed to reduce the input to 50 points.

Because part 1 asks for an intermediate state of the graph after a specific number of connections **starting from the shortest edge**, Kruskal's algorithm cannot be replaced by Prim's, Boruvka's, or reverse-delete in this case.

I observed that the main performance bottleneck of the application is the sorting. Therefore, you may want to attack sorting first if you ever work on improving my design.

<br><br><br></details>

<details>
<summary><b>Day 9:</b> Movie Theater</summary><br>

<h2>Day 9: Movie Theater</h2>

### Summary

For the puzzle of day 9 we work on a matrix of "tiles," which are either red, green, or another irrelevant color. The tiles are ordered in a way so that the red ones constitute a polygon when they are virtually connected with each other consecutively. This polygon is then, including its borders but not its corners, filled with green tiles. The first part of the puzzle asks for the area of the biggest rectangle with red tiles as two of its opposite corners. The second part adds a criteria and asks for the area of the biggest rectangle with opposite red corners and a fully red-green surface.

### My Solution

Here is the state machine in [my solution](src/day09/day09.ml):

```ocaml
module States = struct
  type t =
    | Idle
    | Receive
    | Find_borders
    | Compute
    | Done
  [@@deriving sexp_of, compare, enumerate]
end
```

My design first receives raw text input through the UART bus (In alignment with the ASCII standard, `0x02` means start of text, and `0x03` means end of text.) The FPGA starts its execution in the `Idle` state and immediately starts listening for the start of text character. At the moment of its detection, the design transfers to the state `Receive` and starts saving received values into arrays for x and y coordinates. When the end of text character is received, the FPGA moves onto the state `Find_borders`. In this state, it iterates over all the received red tile coordinates and marks the tiles between them as "border tiles." For example, if we have the red tile constellation:

```text
..............
......2..3....
..............
...0..1.......
..............
...5.....4....
..............
```

It marks the tiles marked with `x` as border tiles:

```text
..............
......2xx3....
......x..x....
...0xx1..x....
...x.....x....
...5xxxxx4....
..............
```

The coordinates of the border tiles are saved into a single-port RAM. Once all borders are figured out, the logic transfers to the state `Compute` where it iterates over all two-combinations of the red tile set with no duplicate pairs, of course. Each pair form a virtual rectangle, and for each one of these virtual rectangles we compute:

- area,
- whether there is any border tile inside.

When all combinations are finally processed, the FPGA transfers to the `Done` state and concludes the computation. As usual, the host is notified about this using a done signal.

### Suggestions

I think the computation in the state `Compute` can be parallelized by delegating it into "computation engines," and I don't even estimate this to be a hard task. I am planning to come back to this puzzle to do this, because the `Compute` state is by far the biggest performance bottleneck of the application.

Another thing: To make testing/debugging reasonably fast, I reduced the input to 50 red tiles. However, my experience is that you can push towards the 512 red tile limit (see Hardcaml solution line 38) if you can tolerate a simulation a bit north of an hour.

<br><br><br></details>

<details>
<summary><b>Day 11:</b> Reactor</summary><br>

<h2>Day 11: Reactor</h2>

### Summary

The first part of puzzle 11 asks us to find the number of all possible paths from node `you` to `out` in a directed acyclic graph. The second part extends the criteria by asking the number of all paths from node `svr` to `out` under the condition that the path has to visit nodes `dac` and `fft` on its way, notwithstanding the order.

### My Solution

[My solution](src/day11/day11.ml) immediately starts listening to the UART bus for the ASCII control character "start of text." When it is finally received, the FPGA starts registering UART values as valid graph data and saves the data into a set of arrays that together serve as the adjacency matrix. When the character "end of text" is received, the FPGA accepts the graph as fully transmitted and starts processing received data to build the topological sorted order for the graph. For this, the logic uses Kahn's algorithm. Here is a nice [article](https://www.geeksforgeeks.org/dsa/topological-sorting-indegree-based-solution/?utm_source=chatgpt.com) about topo sort and Kahn's.

The number of paths from source node A to target node B depends on the number of paths from "the children of A" to B. And the number of paths from the children of node A to node B depends on their children, as well. In software, this is usually implemented using recursion; but because we are in hardware, we process the topological order in reverse instead. Because no parent comes after any of its children in the topological order, crawling the order in reverse guarantees all children are fully processed before a parent node comes up. The number of paths for children are saved in an array for later consumption during the processing of their parent. Once the source node is finally arrived at, this computation is concluded.

I also used a trick. The second part of the puzzle asks for the number of paths from the source node `svr` to target node `out` with the condition the nodes `dac` and `fft` need to be visited along the path. In my reference Python solution, I used a mechanism for each child node to propagate up if these nodes have been seen, but in my Hardcaml solution I did something different: This second part of the puzzle can be reduced to the first part, because:

```text
NP(svr -> dac -> fft -> out) + NP(svr -> fft -> dac -> out) = (NP(svr -> dac) * NP(dac -> fft) * NP(fft -> out)) 
                                                            + (NP(svr -> fft) * NP(fft -> dac) * NP(dac -> out))

NP: number of paths
```

So, after the topological sorted order is complete, the FPGA does three passes over this order to compute:

```text
NP(you -> out)
NP(svr -> dac)
NP(svr -> fft)
NP(dac -> fft)
NP(fft -> dac)
NP(dac -> out)
NP(fft -> out)
```

Finally, these values are used to compute the values required for both parts of the puzzle, and then the host is notified with a done signal.

### Suggestions

I am an electrical engineer; my exposure to concepts such as topological order or Kahn's algorithm does not come from a formal CS training. If you think this could be done better, either through a simpler/better implementation or through a completely different algorithm, please open an issue.

As simulating hardware is very slow, I once again switched real puzzle input with a much smaller toy input.

<br><br><br></details>

## License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
